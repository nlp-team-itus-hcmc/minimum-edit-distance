{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract to abstract levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_special_chars(sentence, keep_under_score):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'(v\\s\\.\\sv\\s.)', '', sentence, re.UNICODE)\n",
    "    if keep_under_score:\n",
    "        sub_string = ''.join(ch for ch in sentence if (unicode.isalnum(ch) or ch == ' ' or ch == '_'))\n",
    "    else:\n",
    "        sub_string = ''.join(ch for ch in sentence if (unicode.isalnum(ch) or ch == ' '))\n",
    "    sub_string_2 = re.sub('\\s{2,}', ' ', sub_string, re.UNICODE)\n",
    "    return sub_string_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list sentence pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_list_pair(sentences1, sentences2, keep_under_score = True):\n",
    "    number_sentences = len(sentences1)\n",
    "    list_sentences = []\n",
    "    for i in range(number_sentences):\n",
    "        s1 = remove_special_chars(sentences1[i], keep_under_score)\n",
    "        s2 = remove_special_chars(sentences2[i], keep_under_score)\n",
    "        s = {'s1': s1, 's2': s2}\n",
    "        list_sentences.append(s)\n",
    "    return list_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(file_name_1, file_name_2, pairs):\n",
    "    fout1 = open(file_name_1, 'w')\n",
    "    fout2 = open(file_name_2, 'w')\n",
    "    for pair in pairs:\n",
    "        s1 = pair['s1'] + '\\n'\n",
    "        s2 = pair['s2'] + '\\n'\n",
    "        fout1.write(s1.encode('utf8'))\n",
    "        fout2.write(s2.encode('utf8'))\n",
    "    fout1.close()\n",
    "    fout2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_pos_tag(sentence):\n",
    "    sub_string = re.sub('/\\w*\\s|/\\w*$', ' ', sentence, re.UNICODE)\n",
    "    return sub_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Về nguyên_nhân thất_bại của U23 Việt_Nam đã được tìm ra : \" Cầu_thủ mất phong_độ thi_đấu \" \" Chọn sai điểm rơi phong_độ \" \" Nhiều cầu_thủ trụ_cột bị chấn_thương \n"
     ]
    }
   ],
   "source": [
    "aa = u'Về/Cm nguyên_nhân/Nn thất_bại/Vv của/Cm U23/Nr Việt_Nam/Nr đã/R được/Vv tìm/Vv ra/R :/PU \"/PU Cầu_thủ/Nn mất/Ve phong_độ/Nn thi_đấu/Vv \"/PU \"/PU Chọn/Vv sai/Aa điểm/Nn rơi/Vv phong_độ/Nn \"/PU \"/PU Nhiều/Aa cầu_thủ/Nn trụ_cột/Nn bị/Vv chấn_thương/Aa'\n",
    "sss = remove_pos_tag(aa)\n",
    "print sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_pos_tag_in_pairs(pairs):\n",
    "    new_pairs = []\n",
    "    for pair in pairs:\n",
    "        s1 = remove_pos_tag(pair['s1'])\n",
    "        s2 = remove_pos_tag(pair['s2'])\n",
    "        s = {'s1': s1, 's2': s2}\n",
    "        new_pairs.append(s)\n",
    "    return new_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentence_1 = []\n",
    "list_sentence_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"vnPara/Sentences1.txt\") as fin:\n",
    "    for line in fin:\n",
    "        list_sentence_1.append(line.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"vnPara/Sentences2.txt\") as fin:\n",
    "    for line in fin:\n",
    "        list_sentence_2.append(line.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083\n",
      "3083\n"
     ]
    }
   ],
   "source": [
    "print len(list_sentence_1)\n",
    "print len(list_sentence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_sentences = len(list_sentence_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_1 = create_list_pair(list_sentence_1, list_sentence_2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('extracted_sentences/abstract_sentences/level1/sentences_1_level_1.txt', 'extracted_sentences/abstract_sentences/level1/sentences_2_level_1.txt', pairs_level_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2: Syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from file was extract to each syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083\n",
      "Một lần nữa cần phải khẳng_định , không có một công_thức chung nào trong nghề sales này cả và sự chuyên_nghiệp của người này không_thể bê nguyên cho người khác .\n",
      "Một lần nữa cần phải khẳng định , không có một công thức chung nào trong nghề sales này cả và sự chuyên nghiệp của người này không thể bê nguyên cho người khác . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin1 = codecs.open(\"vnPara_parsed/Sentences1_syllables.txt\", 'r', encoding='utf-8')\n",
    "list_sentences_1_level2 = []\n",
    "for line in fin1:\n",
    "    list_sentences_1_level2.append(line.strip())\n",
    "    \n",
    "del list_sentences_1_level2[-1] # last sentence only contain '\\n' char, so remove it\n",
    "print len(list_sentences_1_level2)\n",
    "print list_sentences_1_level2[-1]\n",
    "print list_sentence_1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083\n",
      "Cũng như trong bóng_chày , cầu_thủ ném bóng phải chạy về các chốt khoảng bốn lần trong suốt trận_đấu - điều này đồng_nghĩa với việc anh ta nhất_thiết phải chạy về chốt thứ nhất từ ba đến bốn hoặc năm lần trong trận_đấu , dù có đánh trúng hay không .\n",
      "Cũng như trong bóng chày , cầu thủ ném bóng phải chạy về các chốt khoảng bốn lần trong suốt trận đấu – điều này đồng nghĩa với việc anh ta nhất thiết phải chạy về chốt thứ nhất từ ba đến bốn hoặc năm lần trong trận đấu , dù có đánh trúng hay không . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin1 = codecs.open(\"vnPara_parsed/Sentences2_syllables.txt\", 'r', encoding='utf-8')\n",
    "list_sentences_2_level2 = []\n",
    "for line in fin1:\n",
    "    list_sentences_2_level2.append(line.strip())\n",
    "\n",
    "del list_sentences_2_level2[-1] # last sentence only contain '\\n' char, so remove it\n",
    "print len(list_sentences_2_level2)\n",
    "print list_sentences_2_level2[-1]\n",
    "print list_sentence_2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pairs in level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_2 = create_list_pair(list_sentences_1_level2, list_sentences_2_level2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('extracted_sentences/abstract_sentences/level2/sentences_1_level_2.txt', 'extracted_sentences/abstract_sentences/level2/sentences_2_level_2.txt', pairs_level_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from pos file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_1_level_3 = []\n",
    "list_sentences_2_level_3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin2 = codecs.open(\"vnPara_parsed/Sentences1_pos.txt\", 'r', encoding='utf-8')\n",
    "for line in fin2:\n",
    "    list_sentences_1_level_3.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Về/Cm nguyên_nhân/Nn thất_bại/Vv của/Cm U23/Nr Việt_Nam/Nr đã/R được/Vv tìm/Vv ra/R :/PU \"/PU Cầu_thủ/Nn mất/Ve phong_độ/Nn thi_đấu/Vv \"/PU \"/PU Chọn/Vv sai/Aa điểm/Nn rơi/Vv phong_độ/Nn \"/PU \"/PU Nhiều/Aa cầu_thủ/Nn trụ_cột/Nn bị/Vv chấn_thương/Aa \"/PU \"/PU Lịch/Nr thi_đấu/Vv thiếu/Aa khoa_học/Nn \"/PU \"/PU Thiếu/Aa hiểu_biết/Nn về/Cm đối_thủ/Nn \"/PU \"/PU Có/Ve sai_lầm/Nn về/Cm chiến_thuật/Nn \"/PU \"/PU Bản_lĩnh/Nn thi_đấu/Vv yếu_kém/Aa \"/PU ./PU\n",
      "Một/Nq lần/Nn nữa/R cần/Vv phải/Vv khẳng_định/Vv ,/PU không/R có/Ve một/Nq công_thức/Nn chung/Aa nào/Pd trong/Cm nghề/Nn sales/FW này/Pd cả/M và/Cp sự/Nc chuyên_nghiệp/Aa của/Cm người/Nn này/Pd không_thể/R bê/Vv nguyên/Aa cho/Cp người/Nn khác/Aa ./PU\n",
      "3083\n"
     ]
    }
   ],
   "source": [
    "print list_sentences_1_level_3[0]\n",
    "print list_sentences_1_level_3[-1]\n",
    "print len(list_sentences_1_level_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin2 = codecs.open(\"vnPara_parsed/Sentences2_pos.txt\", 'r', encoding='utf-8')\n",
    "for line in fin2:\n",
    "    list_sentences_2_level_3.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Bản_thân/Nn Tổng_giám_đốc/Nn SLNA/Nr Nguyễn_Hồng_Thanh/Nr đã/R phải/Vv kêu_gọi/Vv :/PU \"/PU VFF/Nr có/Ve trách_nhiệm/Nn báo_cáo/Vv Bộ/Nn Văn_hoá/Nn -/PU Thể_thao/Nn và/Cp Du_lịch/Nn Chính_phủ/Nn để/Cm tìm/Vv ra/R hướng/Nn giải_cứu/Vv bóng_đá/Nn Việt_Nam/Nr ./PU\n",
      "Cũng/R như/Cp trong/Cm bóng_chày/Nn ,/PU cầu_thủ/Nn ném/Vv bóng/Nn phải/Vv chạy/Vv về/Cm các/Nq chốt/Nn khoảng/Nn bốn/Nq lần/Nn trong/Cm suốt/Aa trận_đấu/Nn -/PU điều/Nc này/Pd đồng_nghĩa/Aa với/Cp việc/Nn anh/Nn ta/Pp nhất_thiết/R phải/Vv chạy/Vv về/Cm chốt/Vv thứ/Nn nhất/An từ/Cm ba/Nq đến/Cm bốn/Nq hoặc/Cp năm/Nq lần/Nn trong/Cm trận_đấu/Nn ,/PU dù/Cp có/R đánh/Vv trúng/Aa hay/Cp không/R ./PU\n",
      "3083\n"
     ]
    }
   ],
   "source": [
    "print list_sentences_2_level_3[0]\n",
    "print list_sentences_2_level_3[-1]\n",
    "print len(list_sentences_2_level_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove special characters in pos string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_special_char_pos(sentence):\n",
    "    # remove etc\n",
    "    sentence = re.sub('v/Nn\\s./PU\\sv/Nn\\s./PU\\s./PU\\s./PU', '', sentence, re.UNICODE)\n",
    "    sentence = sentence.lower()\n",
    "    # remove special character\n",
    "    sub_string = re.sub('\\W/pu', '', sentence, re.UNICODE)\n",
    "    # remove multispace\n",
    "    sub_string_2 = re.sub('\\s{2,}', ' ', sub_string, re.UNICODE)\n",
    "    return sub_string_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "đúng/aa như/cp câu/nn nói/vv của/cm một/nq vị/nc quan_chức/nn vff/nr tại/cm cuộc/nc họp/vv rút/vv kinh_nghiệm/nn sáng/nt ngày/nt 21/12/2007/nt vấn_đề/nn chính/aa lúc/nt này/pd là/vc phải/vv xác_định/vv cho/vv được/vv bóng_đá/nn việt_nam/nr đang/r ở/cm đâu/pp có/ve cái/nc gì/pp trong/cm tay/nn\n"
     ]
    }
   ],
   "source": [
    "test = remove_special_char_pos(list_sentences_1_level_3[2])\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(number_sentences):\n",
    "    s1_level3 = remove_special_char_pos(list_sentences_1_level_3[i])\n",
    "    s2_level3 = remove_special_char_pos(list_sentences_2_level_3[i])\n",
    "    s = {'s1': s1_level3, 's2': s2_level3}\n",
    "    pairs_level_3.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_3_non_pos_tag = remove_pos_tag_in_pairs(pairs_level_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('extracted_sentences/abstract_sentences/level3/sentences_1_level_3.txt', 'extracted_sentences/abstract_sentences/level3/sentences_2_level_3.txt', pairs_level_3_non_pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse list sentence pair in level 3, remove all except words is Noun, verb, adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_noun(word):\n",
    "    type_nouns = ['/nn', '/nu', '/nq', 'nt', 'nr']\n",
    "    for type_noun in type_nouns:\n",
    "        if word.find(type_noun) != -1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_verb(word):\n",
    "    type_verbs = ['/vd', '/vv', '/vc', '/ve']\n",
    "    for type_verb in type_verbs:\n",
    "        if word.find(type_verb) != -1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_adj(word):\n",
    "    if (word.find('/aa') != -1):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_noun_verb_adj(sentence):\n",
    "    sentence = sentence.strip(' ')\n",
    "    words = sentence.split(' ')\n",
    "    new_sentence = ''\n",
    "    for word in words:\n",
    "        if (is_noun(word)) or (is_verb(word)) or (is_adj(word)):\n",
    "            new_sentence = new_sentence + word + ' '\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "đúng/aa câu/nn nói/vv một/nq quan_chức/nn vff/nr họp/vv rút/vv kinh_nghiệm/nn sáng/nt ngày/nt 21/12/2007/nt vấn_đề/nn chính/aa lúc/nt là/vc phải/vv xác_định/vv cho/vv được/vv bóng_đá/nn việt_nam/nr có/ve tay/nn \n"
     ]
    }
   ],
   "source": [
    "s_4 = keep_noun_verb_adj(pairs_level_3[2]['s1'])\n",
    "print s_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(number_sentences):\n",
    "    s1_level4 = keep_noun_verb_adj(pairs_level_3[i]['s1'])\n",
    "    s2_level4 = keep_noun_verb_adj(pairs_level_3[i]['s2'])\n",
    "    s_level4 = {'s1': s1_level4, 's2': s2_level4}\n",
    "    pairs_level_4.append(s_level4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_4_non_pos_tag = remove_pos_tag_in_pairs(pairs_level_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('extracted_sentences/abstract_sentences/level4/sentences_1_level_4.txt', 'extracted_sentences/abstract_sentences/level4/sentences_2_level_4.txt', pairs_level_4_non_pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse pairs sentence created in level 4, keep noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_one_pos(sentence, type_keep):\n",
    "    sentence = sentence.strip(' ')\n",
    "    words = sentence.split(' ')\n",
    "    new_sentence = ''\n",
    "    if type_keep == 'noun':\n",
    "        for word in words:\n",
    "            if is_noun(word):\n",
    "                new_sentence = new_sentence + word + ' '\n",
    "    if type_keep == 'verb':\n",
    "        for word in words:\n",
    "            if is_verb(word):\n",
    "                new_sentence = new_sentence + word + ' '\n",
    "    if type_keep == 'adj':\n",
    "        for word in words:\n",
    "            if is_adj(word):\n",
    "                new_sentence = new_sentence + word + ' '\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nói/vv họp/vv rút/vv là/vc phải/vv xác_định/vv cho/vv được/vv có/ve \n",
      "câu/nn một/nq quan_chức/nn vff/nr kinh_nghiệm/nn sáng/nt ngày/nt 21/12/2007/nt vấn_đề/nn lúc/nt bóng_đá/nn việt_nam/nr tay/nn \n",
      "đúng/aa chính/aa \n"
     ]
    }
   ],
   "source": [
    "s_5 = keep_one_pos(pairs_level_4[2]['s1'], 'verb')\n",
    "print s_5\n",
    "s_5 = keep_one_pos(pairs_level_4[2]['s1'], 'noun')\n",
    "print s_5\n",
    "s_5 = keep_one_pos(pairs_level_4[2]['s1'], 'adj')\n",
    "print s_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs_one_pos(pairs, type_keep):\n",
    "    pairs_one_pos = []\n",
    "    for pair in pairs:\n",
    "        s1 = keep_one_pos(pair['s1'], type_keep)\n",
    "        s2 = keep_one_pos(pair['s2'], type_keep)\n",
    "        s = {'s1': s1, 's2': s2}\n",
    "        pairs_one_pos.append(s)\n",
    "    return pairs_one_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_5 = make_pairs_one_pos(pairs_level_4, 'noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "câu/nn một/nq quan_chức/nn vff/nr kinh_nghiệm/nn sáng/nt ngày/nt 21/12/2007/nt vấn_đề/nn lúc/nt bóng_đá/nn việt_nam/nr tay/nn \n",
      "bóng_đá/nn việt_nam/nr khi/nt dấu_hiệu/nn đáy/nn \n"
     ]
    }
   ],
   "source": [
    "print pairs_level_5[2]['s1']\n",
    "print pairs_level_5[2]['s2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_5_non_pos_tag = remove_pos_tag_in_pairs(pairs_level_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('extracted_sentences/abstract_sentences/level5/sentences_1_level_5.txt', 'extracted_sentences/abstract_sentences/level5/sentences_2_level_5.txt', pairs_level_5_non_pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_6 = make_pairs_one_pos(pairs_level_4, 'verb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_6_non_pos_tag = remove_pos_tag_in_pairs(pairs_level_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('extracted_sentences/abstract_sentences/level6/sentences_1_level_6.txt', 'extracted_sentences/abstract_sentences/level6/sentences_2_level_6.txt', pairs_level_6_non_pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_7 = make_pairs_one_pos(pairs_level_4, 'adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_level_7_non_pos_tag = remove_pos_tag_in_pairs(pairs_level_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('extracted_sentences/abstract_sentences/level7/sentences_1_level_7.txt', 'extracted_sentences/abstract_sentences/level7/sentences_2_level_7.txt', pairs_level_7_non_pos_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
