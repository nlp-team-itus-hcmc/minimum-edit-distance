{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentence_1 = []\n",
    "list_sentence_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'encoding' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-220-09514e7f9068>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vnPara/Sentences1.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mlist_sentence_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'encoding' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "with open(\"vnPara/Sentences1.txt\") as fin:\n",
    "    for line in fin:\n",
    "        list_sentence_1.append(line.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083\n"
     ]
    }
   ],
   "source": [
    "print len(list_sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"vnPara/Sentences2.txt\") as fin:\n",
    "    for line in fin:\n",
    "        list_sentence_2.append(line.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083\n"
     ]
    }
   ],
   "source": [
    "print len(list_sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_sentences = len(list_sentence_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_level_words(sentence):\n",
    "    print sentence\n",
    "    sentence = sentence.lower()\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    sub_string = re.sub(pattern, ' ', sentence, re.UNICODE)\n",
    "#     sub_string = pattern.sub(' ', string, re.UNICODE)\n",
    "#     sub_string = re.sub(r'([^\\s\\w/])+', '', string, re.UNICODE)\n",
    "#     sub_string = re.sub(r'[\\?\\.\\+:,&%!\\(\\)]', '', string, re.UNICODE)\n",
    "    pattern2 = re.compile('\\s+')\n",
    "    sub_string_2 = re.sub(pattern2, ' ', sub_string, re.UNICODE)\n",
    "#     sub_string_2 = re.search('[\\w\\s]*', string, re.UNICODE)\n",
    "#     sub_string_2 = filter(unicode.isalnum, sentence)\n",
    "#     delchars = ''.join(c for c in map(chr, range(256)) if not c.isalnum())\n",
    "#     print len(delchars)\n",
    "#     str_replace = ' '.join('' for i in range(len(delchars) + 1))\n",
    "#     str_replace = str_replace.decode('utf8')\n",
    "#     print len(str_replace)\n",
    "#     print str_replace\n",
    "#     make_trans = string.maketrans(delchars, str_replace)\n",
    "#     print make_trans\n",
    "#     sentence.translate(delchars)\n",
    "    print sub_string_2\n",
    "    return sub_string_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n",
      "\u000b",
      "\f",
      "\r",
      "\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c",
      "\u001d",
      "\u001e",
      "\u001f !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~��������������������������������������������������������������������������������������������������������������������������������\n"
     ]
    }
   ],
   "source": [
    "delchars = ''.join(c for c in map(chr, range(256)) if not c.isalnum())\n",
    "print delchars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method 'isalnum' of 'unicode' objects>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode.isalnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đúng như câu nói của một vị quan chức VFF tại cuộc họp rút kinh nghiệm ( sáng ngày 21/12/2007 ) : “ Vấn đề chính lúc này là phải xác định cho được bóng đá Việt Nam đang ở đâu có cái gì trong tay\n",
      "\n",
      " ng nh c u n i c a m t v quan ch c vff t i cu c h p r t kinh nghi m s ng ng y 21 12/2007 ) : “ vấn đề chính lúc này là phải xác định cho được bóng đá việt nam đang ở đâu có cái gì trong tay\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u' ng nh c u n i c a m t v quan ch c vff t i cu c h p r t kinh nghi m s ng ng y 21 12/2007 ) : \\u201c v\\u1ea5n \\u0111\\u1ec1 ch\\xednh l\\xfac n\\xe0y l\\xe0 ph\\u1ea3i x\\xe1c \\u0111\\u1ecbnh cho \\u0111\\u01b0\\u1ee3c b\\xf3ng \\u0111\\xe1 vi\\u1ec7t nam \\u0111ang \\u1edf \\u0111\\xe2u c\\xf3 c\\xe1i g\\xec trong tay\\n'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_level_words(list_sentence_1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi hôm nay nói: \"DM DM Dm\"\n"
     ]
    }
   ],
   "source": [
    "a = 'Tôi hôm nay nói: \"DM DM Dm\"'\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi hôm nay nói: DM DM Dm\n"
     ]
    }
   ],
   "source": [
    "b = a.replace('\"', '')\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_level_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(number_sentences):\n",
    "    s1 = make_level_words(list_sentence_1[i])\n",
    "    s2 = make_level_words(list_sentence_2[i])\n",
    "    s = {'s1': s1, 's2': s2}\n",
    "    sentences_level_words.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fout1 = open('extracted_sentences/abstract_sentences/words_level_s1.txt', 'a')\n",
    "fout2 = open('extracted_sentences/abstract_sentences/words_level_s2.txt', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pair in sentences_level_words:\n",
    "    s1 = pair['s1'] + '\\n'\n",
    "    s2 = pair['s2'] + '\\n'\n",
    "    fout1.write(s1.encode('utf8'))\n",
    "    fout2.write(s2.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fout1.close()\n",
    "fout2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract to abstract levels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
